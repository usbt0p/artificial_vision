# Lab 6: Object Detection - YOLO and FCOS

Complete implementation of YOLO and FCOS object detectors trained on COCO dataset.

## ğŸ“ Project Structure

```
lab6_detection/
â”œâ”€â”€ config.py                     # Configuration parameters
â”œâ”€â”€ train.py                      # Training script
â”œâ”€â”€ evaluate.py                   # Evaluation script
â”œâ”€â”€ README.md                     # This file
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ backbone.py              # ResNet backbone
â”‚   â”œâ”€â”€ fpn.py                   # Feature Pyramid Network
â”‚   â”œâ”€â”€ yolo.py                  # YOLO detector
â”‚   â””â”€â”€ fcos.py                  # FCOS detector
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ coco_dataset.py          # COCO data loader
â”‚   â””â”€â”€ transforms.py            # Data augmentation
â”‚
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ yolo_loss.py             # YOLO loss function
â”‚   â””â”€â”€ focal_loss.py            # Focal loss for FCOS
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nms.py                   # NMS and box utilities
â”‚   â”œâ”€â”€ metrics.py               # Evaluation metrics
â”‚   â””â”€â”€ visualization.py         # Plotting utilities
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ coco/                    # COCO dataset (download required)
â”‚       â”œâ”€â”€ train2017/
â”‚       â”œâ”€â”€ val2017/
â”‚       â””â”€â”€ annotations/
â”‚
â”œâ”€â”€ checkpoints/                 # Saved model checkpoints
â”œâ”€â”€ logs/                        # TensorBoard logs
â””â”€â”€ outputs/                     # Predictions and visualizations
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install dependencies
pip install torch torchvision
pip install pycocotools tensorboard matplotlib opencv-python tqdm
```

### 2. Download COCO Dataset

```bash
# Create data directory
mkdir -p data/coco
cd data/coco

# Download images (choose one)
# Full dataset (~25GB)
wget http://images.cocodataset.org/zips/train2017.zip
wget http://images.cocodataset.org/zips/val2017.zip

# Or just validation for testing (~1GB)
wget http://images.cocodataset.org/zips/val2017.zip

# Download annotations
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip

# Extract
unzip train2017.zip
unzip val2017.zip
unzip annotations_trainval2017.zip

cd ../..
```

### 3. Train Model

**Train YOLO:**
```bash
python train.py --model yolo --batch-size 8 --epochs 20
```

**Train FCOS:**
```bash
python train.py --model fcos --batch-size 4 --epochs 20
```

**Resume training:**
```bash
python train.py --model fcos --resume checkpoints/fcos_4bs/checkpoint_epoch_10.pth
```

### 4. Evaluate Model

```bash
python evaluate.py \
    --model fcos \
    --checkpoint checkpoints/fcos_4bs/best.pth \
    --visualize \
    --num-vis 20
```

### 5. Monitor Training

```bash
# Start TensorBoard
tensorboard --logdir logs

# Open browser to http://localhost:6006
```

## ğŸ“Š Expected Results

### YOLO (ResNet18, 20 epochs)
- **mAP**: 15-20%
- **AP50**: 30-35%
- **Training time**: ~2-4 hours (GPU)
- **Inference**: 30-40 FPS

### FCOS (ResNet50, 20 epochs)
- **mAP**: 25-30%
- **AP50**: 42-48%
- **AP75**: 20-25%
- **APS**: 10-15%
- **APM**: 25-30%
- **APL**: 35-40%
- **Training time**: ~4-8 hours (GPU)
- **Inference**: 15-20 FPS

## ğŸ”§ Configuration

Edit `config.py` to change hyperparameters:

```python
# Model settings
num_classes = 80
input_size = 448
grid_size = 7  # YOLO

# Training settings
batch_size = 8
num_epochs = 20
learning_rate = 1e-4

# Loss weights
lambda_coord = 5.0  # YOLO coordinate loss
focal_alpha = 0.25  # FCOS focal loss
focal_gamma = 2.0

# NMS settings
nms_threshold = 0.5
conf_threshold = 0.05
```

## ğŸ“– Usage Examples

### Training with Custom Settings

```bash
python train.py \
    --model fcos \
    --batch-size 4 \
    --epochs 30 \
    --lr 5e-5 \
    --exp-name fcos_long_training
```

### Evaluation with Different Thresholds

```bash
python evaluate.py \
    --model fcos \
    --checkpoint checkpoints/best.pth \
    --conf-threshold 0.1 \
    --nms-threshold 0.6 \
    --save-results \
    --visualize
```

### Using the Models Programmatically

```python
import torch
from models import FCOSDetector, FCOSDecoder
from config import config

# Load model
model = FCOSDetector(num_classes=80)
checkpoint = torch.load('checkpoints/best.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Create decoder
decoder = FCOSDecoder(
    strides=[8, 16, 32],
    conf_threshold=0.05,
    nms_threshold=0.5
)

# Run inference
with torch.no_grad():
    cls_logits, reg_preds, centerness = model(images)
    detections = decoder.decode(cls_logits, reg_preds, centerness)

# Process detections
for det in detections[0]:  # First image
    box, score, label = det
    print(f"Class {label}, Score: {score:.2f}, Box: {box}")
```

## ğŸ› Troubleshooting

### CUDA Out of Memory

```bash
# Reduce batch size
python train.py --model fcos --batch-size 2

# Or use gradient accumulation (modify train.py)
```

### Loss is NaN

Check:
1. Learning rate too high â†’ Try `--lr 1e-5`
2. Gradient explosion â†’ Gradient clipping is enabled by default
3. Bad data â†’ Visualize training samples

### Low mAP (<5%)

Check:
1. Model predictions: `python evaluate.py --visualize`
2. Target encoding: Print targets in loss function
3. NMS threshold: Try `--nms-threshold 0.7`
4. Confidence threshold: Try `--conf-threshold 0.01`

### Training Too Slow

1. Reduce dataset size (edit `config.py`):
```python
# In COCODetectionDataset
self.img_ids = self.img_ids[:1000]  # Use only 1000 images
```

2. Use smaller backbone:
```python
# In config.py
fcos_backbone = 'resnet18'  # Instead of resnet50
```

3. Reduce input size:
```python
input_size = 320  # Instead of 448
```

## ğŸ“ˆ Performance Optimization

### Speed up Training

1. **Mixed Precision Training** (requires Apex or PyTorch >= 1.6):
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    loss = model(images, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

2. **Multi-GPU Training**:
```python
model = nn.DataParallel(model)
```

3. **Increase num_workers**:
```bash
python train.py --num-workers 8
```

### Improve Accuracy

1. **Longer training**: `--epochs 50`
2. **Data augmentation**: Edit `datasets/transforms.py`
3. **Larger backbone**: Use ResNet101
4. **Multi-scale training**: Train on multiple input sizes
5. **Better optimizer**: Try SGD with momentum

## ğŸ“š Architecture Details

### YOLO

- **Grid-based detection**: Divides image into 7Ã—7 grid
- **Multi-component loss**: Localization + confidence + classification
- **Advantages**: Simple, fast
- **Disadvantages**: Struggles with small objects, multiple objects per cell

### FCOS

- **Anchor-free**: Per-pixel prediction
- **Feature Pyramid**: Multi-scale detection (P3, P4, P5)
- **Center-ness**: Quality score for predictions
- **Focal Loss**: Handles class imbalance
- **Advantages**: Better small object detection, no anchor tuning
- **Disadvantages**: Slower than YOLO, more complex

## ğŸ”¬ Advanced Features

### Soft-NMS

Already implemented in `utils/nms.py`:

```python
from utils.nms import soft_nms

keep, updated_scores = soft_nms(boxes, scores, sigma=0.5)
```

### Class-wise NMS

```python
from utils.nms import batched_nms

keep = batched_nms(boxes, scores, labels, iou_threshold=0.5)
```

### Custom Metrics

```python
from utils.metrics import DetectionMetrics

metrics = DetectionMetrics(num_classes=80)
metrics.update(pred_boxes, pred_scores, pred_labels, gt_boxes, gt_labels)
results = metrics.get_results()
```

## ğŸ“ File Descriptions

### Core Files

- **config.py**: All hyperparameters and paths
- **train.py**: Training loop with logging
- **evaluate.py**: Evaluation with COCO metrics

### Models

- **backbone.py**: ResNet feature extractors
- **fpn.py**: Feature Pyramid Network
- **yolo.py**: YOLO detector + decoder
- **fcos.py**: FCOS detector + decoder

### Datasets

- **coco_dataset.py**: COCO data loader
- **transforms.py**: Image transformations

### Losses

- **yolo_loss.py**: YOLO multi-part loss
- **focal_loss.py**: Focal loss + FCOS loss

### Utils

- **nms.py**: NMS variants and box utilities
- **metrics.py**: Evaluation metrics
- **visualization.py**: Plotting functions

## ğŸ“ Learning Resources

### Papers

1. **YOLO**: [You Only Look Once (2016)](https://arxiv.org/abs/1506.02640)
2. **FCOS**: [FCOS: Fully Convolutional One-Stage (2019)](https://arxiv.org/abs/1904.01355)
3. **FPN**: [Feature Pyramid Networks (2017)](https://arxiv.org/abs/1612.03144)
4. **Focal Loss**: [Focal Loss for Dense Detection (2017)](https://arxiv.org/abs/1708.02002)

### Documentation

- [PyTorch Docs](https://pytorch.org/docs/)
- [COCO Dataset](https://cocodataset.org/)
- [TorchVision Models](https://pytorch.org/vision/stable/models.html)

## ğŸ¤ Contributing

This is a lab project for educational purposes. Suggestions and improvements are welcome!

## ğŸ“„ License

Educational use only. COCO dataset has its own license.

## ğŸ™ Acknowledgments

- COCO dataset team
- PyTorch team
- Original paper authors

## ğŸ“ Support

For questions about this lab:
- Check troubleshooting section
- Review lecture materials
- Ask during office hours

---

**Good luck with your object detection implementation! ğŸ¯**






-----------

ğŸ¯ Key Features Implemented
Models

âœ… YOLO: Grid-based detection with ResNet backbone
âœ… FCOS: Anchor-free with FPN multi-scale detection
âœ… ResNet18/50 backbones with pretrained weights
âœ… Feature Pyramid Network (FPN)

Loss Functions

âœ… YOLO multi-component loss (coord + conf + class)
âœ… Focal loss for class imbalance
âœ… GIoU loss for better box regression
âœ… Center-ness prediction

Training Pipeline

âœ… Complete training loop with validation
âœ… TensorBoard logging
âœ… Checkpoint saving/loading
âœ… Learning rate scheduling
âœ… Gradient clipping

Evaluation

âœ… COCO API integration
âœ… mAP, AP50, AP75 metrics
âœ… Scale-specific metrics (APS, APM, APL)
âœ… Visualization of predictions

Utilities

âœ… NMS (hard and soft variants)
âœ… Batched NMS per class
âœ… IoU computation (multiple formats)
âœ… Box format conversions
âœ… Detection metrics

ğŸ“Š What Students Will Learn

Data Handling: COCO format, batch collation, augmentation
Model Architecture: Backbone, FPN, detection heads
Loss Design: Multi-task learning, focal loss, GIoU
Training: Proper training loops, validation, logging
Evaluation: COCO metrics, mAP computation
Post-processing: NMS, confidence thresholding

ğŸ“ Expected Outcomes
After 20 epochs:

YOLO: 15-20% mAP
FCOS: 25-30% mAP

Students will understand:

Why FCOS performs better on small objects
How anchor-free detectors work
The importance of multi-scale features
How to handle class imbalance

ğŸ“ All Files Are Ready!
You can now:

Copy each file into your local directory
Follow the Quick Start Guide
Refer to README.md for detailed documentation

All files are production-ready with proper error handling, documentation, and following best practices. Students can start training immediately after setup! ğŸ‰